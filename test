from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# Set up Selenium WebDriver
driver = webdriver.Chrome()  # You need to have chromedriver installed and in PATH
url = "https://data.census.gov/table/ACSST1Y2022.S1501"
driver.get(url)

# Wait for the table to load
wait = WebDriverWait(driver, 10)
wait.until(EC.presence_of_element_located((By.CLASS_NAME, "table-responsive")))

# Get page source
page_source = driver.page_source

# Close Selenium WebDriver
driver.quit()

# Parse page source with BeautifulSoup
soup = BeautifulSoup(page_source, 'html.parser')

# Find the table containing the data
table = soup.find('table', {'class': 'table'})

# Extract data from the table
data = []
for row in table.find_all('tr'):
    data_row = []
    for cell in row.find_all(['th', 'td']):
        data_row.append(cell.text.strip())
    if data_row:
        data.append(data_row)

# Print the scraped data
for row in data:
    print('\t'.join(row))







from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
import time

# Set up the WebDriver (this example uses Chrome)
service = Service('/path/to/chromedriver')  # Specify the path to the ChromeDriver
driver = webdriver.Chrome(service=service)

# Open the Census data page
url = 'https://data.census.gov/table/ACSST1Y2021.S1501'
driver.get(url)

# Wait for the table to load
try:
    element_present = EC.presence_of_element_located((By.CSS_SELECTOR, 'table'))
    WebDriverWait(driver, 10).until(element_present)
except TimeoutException:
    print("Timed out waiting for page to load")
    driver.quit()

# Now we need to locate the table and extract its content
table = driver.find_element(By.CSS_SELECTOR, 'table')

# Extract the table headers
headers = table.find_elements(By.TAG_NAME, 'th')
header_list = [header.text for header in headers]

# Extract the table rows
rows = table.find_elements(By.TAG_NAME, 'tr')
data = []
for row in rows:
    cells = row.find_elements(By.TAG_NAME, 'td')
    data.append([cell.text for cell in cells])

# Close the driver
driver.quit()

# Print the extracted data
print(header_list)
for row in data:
    print(row)
